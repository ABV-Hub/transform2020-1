{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning a shapefile\n",
    "\n",
    "DATE: 11 June 2020, 18:00 - 21:00 UTC\n",
    "\n",
    "AUDIENCE: Intermediate\n",
    "\n",
    "INSTRUCTOR: Martin Bentley, Digital Geoscientist, [Agile](https://agilescientific.com/)\n",
    "\n",
    "When processing data, we are often not lucky enough to have it perfectly useable immediately. This notebook works through loading, cleaning and saving a shapefile, using `geopandas`, an extension for `pandas` that adds facility for spatial processing.\n",
    "\n",
    "#### Note\n",
    "Much of this is standard data cleaning, and does not rely on geopandas per se, except that the data that we want to clean is in a geospatial data format, such as a shapefile. Most of these tools are the same in standard `pandas`, but have been extended in geopandas to work with spatial indices.\n",
    "\n",
    "This notebook is provided more as an example of data cleaning, which is common when dealing with real data. The result of this notebook can easily be used in whatever GIS software you prefer, since it is a standard shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start by loading and having a look at the data that we have available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "fname = '../data/offshore_wells_2011_UTM20_NAD83.shp'\n",
    "\n",
    "well_data = gpd.read_file(fname)\n",
    "well_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something that we may be interested in is the different companies that have operated in this field. This is equivalent to looking at a column in a spreadsheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "well_data['Company']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to get an idea of all the companies present, we can use the `set` function, which returns the unique values from a list-like object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "set(well_data['Company'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A number of these companies should probably be consolidated. The most straightforward way to do this is by diving into the dark art of regular expressions. We will make a dictionary of what to look for as the key and what to replace it with as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replacements = {\n",
    "    r'\\-': '', #  remove '-'\n",
    "    r' et al': '', #  remove ' et al'\n",
    "    r' Cda': '', #  remove ' Cda'\n",
    "    r'EnCana.*$': 'EnCana', #  change 'EnCana' followed by anything to 'EnCana'\n",
    "    r'PanCanadian(\\-|.*)\\n.*': 'PanCanadian', #  strip the odd characters after 'PanCanadian'\n",
    "    r'Mobil.*$': 'Mobil', #  strip anything following 'Mobil'\n",
    "    r'Shell.*$': 'Shell', #  strip anything following 'Shell'\n",
    "    r'Exxonmobil': 'ExxonMobil', #  correct capitalisation of 'Exxonmobil' to 'ExxonMobil'\n",
    "    r'Petocan': 'PetroCan', #  correct spelling\n",
    "    r'Petrocan': 'PetroCan', #  correct capitalisation of 'Petrocan' to 'PetroCan'\n",
    "    r'PetroCan*$': 'PetroCan', #  strip anything following 'PetroCan'\n",
    "    r'^Husky.*\\n.*$': 'HBV', #  convert anything starting with 'Husky' to 'HBV' after stripping new line\n",
    "    r'^Bow Valley.*\\n.*$': 'BVH', #  convert anything starting with 'Bow Valley' to 'BVH' after stripping new line\n",
    "    r'HBV.*$': 'HBV', #  strip anything following 'HBV'\n",
    "    r'BVH.*$': 'BVH', #  strip anything following 'BVH'\n",
    "    r'Pex/Tex': 'Pex', #  convert 'Pex/Tex' to 'Pex'\n",
    "    r'Candian Sup/': 'Canadian Superior', #  correct typo 'Candian Sup/' to 'Canadian Superior'\n",
    "    r'Canadian Sup\\.': 'Canadian Superior', #  expand 'Canadian Sup.' to 'Canadian Superior'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we are going to create a new column (`Owner`) to store the cleaned data, in case we need to retrieve the exact company for some reason. We could change the original GeoDataFrame column by using the `inplace=True` argument to the `replace` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "well_data['Owner'] = well_data['Company'].replace(regex=replacements)\n",
    "set(well_data['Owner'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1\n",
    "\n",
    "1. Print a list of the unique values in the `Well_Type` Series.\n",
    "2. Clean up the `Well_Type` Series to remove the typos and make the data more consistent. We can do this in-place, because the original data does not really give us any additional information. (Hint: look at the `inplace=True` parameter to do this to the original GeoDataFrame.)\n",
    "    - Change 'Exploratory' to 'Exploration'\n",
    "    - Change the typo 'Develpoment' to 'Development'\n",
    "    - Remove the new line, by changing `\\n&` to `''`\n",
    "    - Remove excess whitespace by changing `\\s+` to `' '`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a list of the unique values in the `Well_Type` Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Print a list of the unique values in the `Well_Type` Series.\n",
    "set(well_data['Well_Type'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up the `Well_Type` Series to remove typos and make the data more consistent. Do this in-place.\n",
    "# \n",
    "replacements = {\n",
    "    'key': 'changed_to',\n",
    "    r'\\n&': '',\n",
    "    r'\\s+': ' ',\n",
    "    'key2': 'changed_to',\n",
    "}\n",
    "\n",
    "well_data['Well_Type'].replace(regex=replacements, inplace=True)\n",
    "well_data['Well_Type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Clean up the `Well_Type` Series to remove typos and make the data more consistent. Do this in-place.\n",
    "replacements = {\n",
    "    'Develpoment\\/ ': 'Development\\/',\n",
    "    r'\\n&': '',\n",
    "    r'\\s+': ' ',\n",
    "    'Exploratory': 'Exploration',\n",
    "}\n",
    "\n",
    "well_data['Well_Type'].replace(regex=replacements, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Column Names\n",
    "\n",
    "The current column names are not very helpful in some cases, with weird codes and similar. We can probably make these more understandable, and (geo)pandas makes it easy to do so.\n",
    "\n",
    "#### Note for Shapefile\n",
    "The maximim length of field names in a shapefile is 10 characters. Some other formats, such as `.gpkg` do not have this limitation.\n",
    "\n",
    "______________\n",
    "\n",
    "We can start by getting the current column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "print(well_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these are clearly cut off due to needing to be less than 10 characters in length, for example `Well_Termi` and `seafl_twt_`. In other cases, we can see that there are duplicates, for example `Well_Name` and `Well_Nam_1`, without any indication of what the difference is. We can do better, even with the limits of the Shapefile format.\n",
    "\n",
    "We can get a feel for the data with the `head()` method, as used above. The `set()` method is also often helpful to see what different values are in text columns, and may give us a better idea what the data is describing, as we have already seen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a `rename()` method that can take a `dict` of existing Series names as keys and set a new name as the values. We will change the `Well_Termi` to `Well_End` and `Well_Nam_1` to `Well_Code`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "series_names = {\n",
    "    'Well_Termi': 'Well_End',\n",
    "    'Well_Nam_': 'Well_Code',\n",
    "}\n",
    "well_data.rename(columns=series_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, `well_data` is not changed, since `rename()` returns a copy of the GeoDataFrame. To change it instead of getting a copy, the `inplace=True` option should be added, or the copy assigned to another variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_data.rename(columns=series_names, inplace=True)\n",
    "# We can also do this with the following:\n",
    "# well_data = well_data.rename(columns=series_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it works!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(well_data.columns)\n",
    "well_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "1. What are the different values of `Well_Symb`?\n",
    "2. What are the different values of `Drilling_U`? In particular, what are the different entries in `Drilling_U` referring to, and what might be a more descriptive name?\n",
    "3. Change the following column names in the DataFrame:\n",
    "    * `Total_De_1` to `Dpth_ft`\n",
    "    * `Total_Dept` to `Dpth_m`\n",
    "    * `seafl_twt_` to `FloorTWT`\n",
    "    * `Drilling_U` to something based on the previous answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the different values in `Well_Symb`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# What are the different values in `Well_Symb`?\n",
    "set(well_data['Well_Symb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What are the different values in `Drilling_U`?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# What are the different values in `Drilling_U`?\n",
    "set(well_data['Drilling_U'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series_names = {\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "series_names = {\n",
    "    'Drilling_U': 'Drill_Ship',\n",
    "    'Total_De_1': 'Dpth_ft',\n",
    "    'Total_Dept': 'Dpth_m',\n",
    "    'Water_Dept': 'Water_Dpth',\n",
    "    'seafl_twt_': 'FloorTWT',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are changing a Shapefile, remember that we can not have Series names longer than 10 characters. This will check it for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for series in series_names:\n",
    "    if len(series) > 10:\n",
    "        print(f'{series} longer than 10 characters. Will not be able to save as Shapefile.')\n",
    "    else:\n",
    "        well_data.rename(columns=series_names, inplace=True)\n",
    "well_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datetimes\n",
    "\n",
    "If you are familiar with `pandas`, then you will know the utility of `datetime`s. We have some dates in the data, so we should make sure that they are correctly imported if we want to use that for anything involving time series analysis.\n",
    "\n",
    "#### Note:\n",
    "It is not possible to write a `datetime` to a Shapefile. If you want to do analysis that uses timeseries, then you may want to save a cleaned dataframe _before_ you convert to `datetime`s. Alternatively, save the GeoDataFrame as a geopackage or similar format that can handle a `datetime`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "type(well_data['Spud_Date'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see, these dates are stored as strings. We can easily convert them to `datetime`s, however. First we will copy our original geodataframe to save later. (If you are doing this conversion with your own data, make sure that you look into the limitations of doing so, if you want to save a shapefile.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "well_data_original = well_data.copy()\n",
    "well_data['Spud_Date'] = pd.to_datetime(well_data['Spud_Date'])\n",
    "type(well_data['Spud_Date'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3\n",
    "\n",
    "1. Change the `Well_End` Series to `Timestamp`s.\n",
    "2. Make a Series of the difference in time between the `Spud_Date` and the `Well_End` Series. (Do not add this to our current geodataframe, to make saving it easier later.)\n",
    "3. What is the biggest difference in days, between the `Spud_Date` and the `Well_End`  Series? (Hint: you may wish to look at the `dt.days` attribute of a `timeDelta`.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the `Well_End` Series to `Datetime`s.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Change the `Well_End` Series to `Timestamp`s.\n",
    "well_data['Well_End'] = pd.to_datetime(well_data['Well_End'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a Series with the difference in time between the `Spud_Date` and `Well_End` Series.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# Add a Series with the difference in time between the `Spud_Date` and `Well_End` Series.\n",
    "time_differences = well_data['Well_End'] - well_data['Spud_Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the biggest time difference, in days, between the `Spud_Date` and `Well_End` Series?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# What is the biggest time difference, in days, between the `Spud_Date` and `Well_End` Series?\n",
    "max(time_differences.dt.days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving files\n",
    "\n",
    "Once we have made these changes, we would like to save them for future work. Geopandas makes that very easy. Note that we can not write a `datetime` to shapefiles, so we would need to change it (back) to a string if we want to save it. Similarly, if we have a Series of `bool` values (`True` or `False`) we should convert those to `int`s before we save.\n",
    "\n",
    "First we will see what available options we have to save to. Geopandas uses `fiona` in the background; we will take a look at what that offers us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiona #  we do not normally need this for saving, it gets used in the background.\n",
    "fiona.supported_drivers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can only write to some of these formats: those with `raw` or `rw` tags.\n",
    "\n",
    "As a format, `gpkg` is becoming more popular, so we will save our geodataframe as that. One nice advantage, not relevant here, is being able to save multiple layers in a single file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "fname = '../data/cleaned/gpkg-offshore_wells_2011_UTM20_NAD83.gpkg'\n",
    "\n",
    "well_data.to_file(fname, layer='well_locations', driver='GPKG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also save as a Shapefile, but we will get an error:\n",
    "\n",
    "`DriverSupportError: ESRI Shapefile does not support datetime fields`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "fname = '../data/cleaned/offshore_wells_2011_UTM20_NAD83_cleaned.shp'\n",
    "\n",
    "well_data.to_file(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is fixable by saving our copy of the dataset, or by converting the datetime back to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "# well_data['Spud_Date'] = well_data['Spud_Date'].dt.strftime('%Y-%m-%d')\n",
    "# well_data['Well_End'] = well_data['Well_End'].dt.strftime('%Y-%m-%d')\n",
    "fname = '../data/offshore_wells_2011_UTM20_NAD83_cleaned.shp'\n",
    "\n",
    "well_data_original.to_file(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily save these using a different CRS, if that is better for our data. This is one for the North America Datum 1927, in degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "fname = '../data/offshore_wells_2011_Geographic_NAD27_cleaned.shp'\n",
    "\n",
    "well_data_original.to_crs(epsg=4267).to_file(fname, driver='ESRI Shapefile')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Closing remarks\n",
    "\n",
    "The data that we have just saved can be used in the \"Intro to Geopandas\" notebook.\n",
    "\n",
    "<hr />\n",
    "<img src=\"https://avatars1.githubusercontent.com/u/1692321?v=3&s=200\" style=\"float:center\" width=\"40px\" />\n",
    "<p><center>© 2020 <a href=\"http://www.agilegeoscience.com/\">Agile Geoscience</a> — <a href=\"https://creativecommons.org/licenses/by/4.0/\">CC-BY</a></center></p>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
